{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Day 4: PlanDay Compilation with GEPA\n",
    "\n",
    "**Goal**: Compile PlanDay module to improve event time preservation and location accuracy  \n",
    "**Optimizer**: GEPA with budget=40 rollouts  \n",
    "**Expected Runtime**: 4-6 hours\n",
    "\n",
    "## Target Performance\n",
    "- Uncompiled baseline: ~60-70% time/location preservation\n",
    "- Compiled target: >85% preservation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup: Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "!pip install -q dspy-ai sentence-transformers accelerate\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mount Google Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# Create directories\n",
    "!mkdir -p /content/drive/MyDrive/mini-town/compiled\n",
    "!mkdir -p /content/drive/MyDrive/mini-town/checkpoints\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upload Seed File and Set API Key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set Together.ai API key for GEPA reflection LM\n",
    "os.environ['TOGETHER_API_KEY'] = getpass('Enter your TOGETHER_API_KEY: ')\n",
    "print(\"✅ API keys configured\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "import os\n",
    "from getpass import getpass\n",
    "\n",
    "# Upload planner seeds\n",
    "print(\"Upload planner_seeds_v1.json:\")\n",
    "uploaded = files.upload()\n",
    "\n",
    "# Set API key\n",
    "os.environ['GROQ_API_KEY'] = getpass('Enter your GROQ_API_KEY: ')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configure DSPy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dspy\n",
    "\n",
    "lm = dspy.LM(\n",
    "    model=\"groq/llama-3.1-8b-instant\",\n",
    "    api_key=os.getenv('GROQ_API_KEY'),\n",
    "    temperature=0.3,\n",
    "    max_tokens=512\n",
    ")\n",
    "\n",
    "dspy.settings.configure(lm=lm)\n",
    "print(\"✅ DSPy configured with Groq LLM\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define PlanDay Signature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PlanDay(dspy.Signature):\n",
    "    \"\"\"Create a time-blocked plan preserving exact event times and locations.\n",
    "    \n",
    "    CRITICAL: When invited to an event, use the EXACT TIME from the invitation.\n",
    "    Include coordinates in format (x, y) for all locations.\n",
    "    \"\"\"\n",
    "    \n",
    "    agent_goal: str = dspy.InputField(desc=\"Agent's high-level goal\")\n",
    "    agent_personality: str = dspy.InputField(desc=\"Agent's personality traits\")\n",
    "    current_time: str = dspy.InputField(desc=\"Current time (e.g., '2:30 PM')\")\n",
    "    current_location: str = dspy.InputField(desc=\"Current location coordinates\")\n",
    "    recent_events: str = dspy.InputField(desc=\"Recent invitations with exact times\")\n",
    "    relevant_memories: str = dspy.InputField(desc=\"Relevant memories\")\n",
    "    \n",
    "    reasoning: str = dspy.OutputField(desc=\"Explain time preservation\")\n",
    "    plan: str = dspy.OutputField(desc=\"Time-blocked plan with coordinates\")\n",
    "\n",
    "print(\"✅ PlanDay signature defined\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Seeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('planner_seeds_v1.json', 'r') as f:\n",
    "    seeds_data = json.load(f)\n",
    "\n",
    "trainset = []\n",
    "for seed in seeds_data['seeds']:\n",
    "    example = dspy.Example(\n",
    "        agent_goal=seed['agent_goal'],\n",
    "        agent_personality=seed['agent_personality'],\n",
    "        current_time=seed['current_time'],\n",
    "        current_location=seed['current_location'],\n",
    "        recent_events='\\n'.join([f\"- {e}\" for e in seed['recent_events']]),\n",
    "        relevant_memories='\\n'.join([f\"- {m}\" for m in seed['relevant_memories']]),\n",
    "        gold_plan=seed['gold_plan']\n",
    "    ).with_inputs('agent_goal', 'agent_personality', 'current_time', 'current_location', 'recent_events', 'relevant_memories')\n",
    "    trainset.append(example)\n",
    "\n",
    "print(f\"✅ Loaded {len(trainset)} training examples\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "TIME_PATTERN = re.compile(r\"\\b(\\d{1,2}:\\d{2}\\s*[AP]M)\\b\", re.IGNORECASE)\n",
    "LOCATION_PATTERN = re.compile(r\"\\((\\d+(?:\\.\\d+)?),\\s*(\\d+(?:\\.\\d+)?)\\)\")\n",
    "\n",
    "def extract_times(text):\n",
    "    return [m.strip() for m in TIME_PATTERN.findall(text)]\n",
    "\n",
    "def extract_locations(text):\n",
    "    return [f\"({m[0]}, {m[1]})\" for m in LOCATION_PATTERN.findall(text)]\n",
    "\n",
    "def planning_metric(example, pred, trace=None):\n",
    "    plan_text = pred.plan if hasattr(pred, 'plan') else \"\"\n",
    "    if not plan_text:\n",
    "        return 0.0\n",
    "    \n",
    "    total_checks = 0\n",
    "    satisfied = 0\n",
    "    \n",
    "    for event in example.recent_events.split('\\n'):\n",
    "        event = event.strip()\n",
    "        if not event or event.startswith('#'):\n",
    "            continue\n",
    "        \n",
    "        event_times = extract_times(event)\n",
    "        event_locations = extract_locations(event)\n",
    "        \n",
    "        if event_times:\n",
    "            total_checks += 1\n",
    "            if any(t in plan_text for t in event_times):\n",
    "                satisfied += 1\n",
    "        \n",
    "        if event_locations:\n",
    "            total_checks += 1\n",
    "            if any(loc in plan_text for loc in event_locations):\n",
    "                satisfied += 1\n",
    "    \n",
    "    if total_checks == 0:\n",
    "        return 1.0 if example.agent_goal.split()[0].lower() in plan_text.lower() else 0.5\n",
    "    \n",
    "    return satisfied / total_checks\n",
    "\n",
    "print(\"✅ Metric defined\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Uncompiled Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uncompiled_planner = dspy.Predict(PlanDay)\n",
    "print(\"✅ Uncompiled baseline created\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate Uncompiled Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_planner(module, testset):\n",
    "    scores = []\n",
    "    for example in testset:\n",
    "        try:\n",
    "            pred = module(\n",
    "                agent_goal=example.agent_goal,\n",
    "                agent_personality=example.agent_personality,\n",
    "                current_time=example.current_time,\n",
    "                current_location=example.current_location,\n",
    "                recent_events=example.recent_events,\n",
    "                relevant_memories=example.relevant_memories\n",
    "            )\n",
    "            score = planning_metric(example, pred)\n",
    "            scores.append(score)\n",
    "        except Exception as e:\n",
    "            print(f\"Error: {e}\")\n",
    "            scores.append(0.0)\n",
    "    \n",
    "    avg = sum(scores) / len(scores)\n",
    "    high_quality = sum(1 for s in scores if s >= 0.9)\n",
    "    return {'avg': avg, 'high_quality_pct': high_quality / len(scores) * 100}\n",
    "\n",
    "print(\"Evaluating uncompiled baseline...\")\n",
    "uncompiled_results = evaluate_planner(uncompiled_planner, trainset)\n",
    "print(f\"Avg Score: {uncompiled_results['avg']:.2f}\")\n",
    "print(f\"High Quality: {uncompiled_results['high_quality_pct']:.1f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run GEPA Compilation (4-6 hours)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dspy.teleprompt import GEPA\n",
    "import time\n",
    "import os\n",
    "import dspy\n",
    "\n",
    "# Configure reflection LM (uses Together.ai model)\n",
    "reflection_lm = dspy.LM(\n",
    "    model=\"together_ai/meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo\",\n",
    "    api_key=os.getenv(\"TOGETHER_API_KEY\"),\n",
    "    temperature=0.5  # Slightly higher temp for creative reflection\n",
    ")\n",
    "\n",
    "# GEPA optimizer with correct configuration\n",
    "optimizer = GEPA(\n",
    "    metric=planning_metric,\n",
    "    auto=\"medium\",               # Use preset budget (\"light\", \"medium\", or \"heavy\")\n",
    "    reflection_minibatch_size=5, # Number of examples per reflection round\n",
    "    track_stats=True,            # Enable detailed logging\n",
    "    reflection_lm=reflection_lm  # Required for GEPA\n",
    ")\n",
    "\n",
    "print(\"✅ GEPA optimizer initialized\")\n",
    "print(\"Budget level: medium\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run GEPA Compilation\n",
    "\n",
    "⚠️ **This will take several hours**  \n",
    "💾 Progress saved to Google Drive automatically"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run GEPA compilation\n",
    "print(\"🚀 Starting GEPA compilation...\")\n",
    "print(\"This will take several hours. You can monitor progress in the output below.\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "compiled_planner = optimizer.compile(\n",
    "    student=uncompiled_planner,\n",
    "    trainset=trainset\n",
    ")\n",
    "\n",
    "elapsed = time.time() - start_time\n",
    "print(f\"\\n✅ Compilation complete!\")\n",
    "print(f\"Time elapsed: {elapsed/3600:.2f} hours\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate Compiled Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Evaluating compiled module...\")\n",
    "compiled_results = evaluate_planner(compiled_planner, trainset)\n",
    "print(f\"Avg Score: {compiled_results['avg']:.2f}\")\n",
    "print(f\"High Quality: {compiled_results['high_quality_pct']:.1f}%\")\n",
    "\n",
    "improvement = compiled_results['high_quality_pct'] - uncompiled_results['high_quality_pct']\n",
    "print(f\"\\nImprovement: +{improvement:.1f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Compiled Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to Google Drive\n",
    "save_path = '/content/drive/MyDrive/mini-town/compiled/compiled_planner.json'\n",
    "compiled_planner.save(save_path)\n",
    "print(f\"✅ Saved to: {save_path}\")\n",
    "\n",
    "# Save prompt for inspection\n",
    "prompt_path = '/content/drive/MyDrive/mini-town/compiled/prompt_planner.txt'\n",
    "with open(prompt_path, 'w') as f:\n",
    "    f.write(str(compiled_planner.dump_state()))\n",
    "print(f\"✅ Prompt saved to: {prompt_path}\")\n",
    "\n",
    "# Save results\n",
    "results = {\n",
    "    'compilation_time_hours': elapsed / 3600,\n",
    "    'uncompiled': uncompiled_results,\n",
    "    'compiled': compiled_results,\n",
    "    'improvement_pct': improvement\n",
    "}\n",
    "\n",
    "results_path = '/content/drive/MyDrive/mini-town/compiled/planner_results.json'\n",
    "with open(results_path, 'w') as f:\n",
    "    json.dump(results, f, indent=2)\n",
    "print(f\"✅ Results saved to: {results_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download compiled files\n",
    "files.download('/content/drive/MyDrive/mini-town/compiled/compiled_planner.json')\n",
    "files.download('/content/drive/MyDrive/mini-town/compiled/prompt_planner.txt')\n",
    "files.download('/content/drive/MyDrive/mini-town/compiled/planner_results.json')\n",
    "\n",
    "print(\"✅ Done! Copy compiled_planner.json to your project's compiled/ directory\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
